{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347f73e8",
   "metadata": {},
   "source": [
    "#### 分类-声呐数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正确显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fa5b3",
   "metadata": {},
   "source": [
    "##### K-近邻算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/分类/sonar.all-data.csv',header=None)\n",
    "\n",
    "# 提取特征与标签\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "# 标签转换为0/1\n",
    "from sklearn.preprocessing import LabelEncoder  # 用于标签编码\n",
    "# 初始化编码器\n",
    "le = LabelEncoder()\n",
    "# 拟合并转换标签（将字符映射为整数，如 'M'→1, 'B'→0，具体映射可通过 classes_ 属性查看）\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# （可选）查看编码映射关系，确认转换是否正确\n",
    "print(\"标签编码映射：\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# 划分训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 训练模型\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print('不做交叉验证的准确率:',knn_clf.score(X_test, y_test))\n",
    "\n",
    "# 网格搜索&交叉验证\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1:曼哈顿距离，2:欧氏距离\n",
    "}\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"================================================\")\n",
    "print('最佳参数:',grid_search.best_params_)\n",
    "print('最佳分数:',grid_search.best_score_)\n",
    "print('准确率:',grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a55ccf",
   "metadata": {},
   "source": [
    "##### 决策树分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c744af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('data/分类/sonar.all-data.csv', header=None)\n",
    "\n",
    "# 特征提取\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "# 标签转换\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# 定义模型\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 定义参数搜索空间\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "   'max_depth': [2, 4, 6, 8, 10, None],\n",
    "   'min_samples_split': [2, 4, 6, 8, 10],\n",
    "   'min_samples_leaf': [1, 2, 4, 6, 8, 10]\n",
    "}\n",
    "\n",
    "# 定义网格搜索\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv=5)\n",
    "\n",
    "# 训练模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print('最佳参数:', grid_search.best_params_)\n",
    "print('准确率:', accuracy_score(y_test, y_pred))\n",
    "print('分类报告:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier  # 改为决策树分类器\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('data/分类/sonar.all-data.csv', header=None)\n",
    "\n",
    "# 提取特征与标签\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# 标签转换为0/1\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"标签编码映射：\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# 划分训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立决策树分类模型\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "# 评估模型\n",
    "print('不做调参的准确率:', accuracy_score(y_test, y_pred))\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# 网格搜索&交叉验证\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],           # 树的最大深度\n",
    "    'min_samples_split': [2, 5, 10],            # 分裂所需最小样本数\n",
    "    'min_samples_leaf': [1, 2, 4],              # 叶节点最小样本数\n",
    "    'criterion': ['gini', 'entropy']            # 分裂标准\n",
    "}\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(dt_clf, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"================================================\")\n",
    "print('最佳参数:', grid_search.best_params_)\n",
    "print('最佳交叉验证准确率:', grid_search.best_score_)\n",
    "print('测试集准确率:', grid_search.score(X_test, y_test))\n",
    "\n",
    "# 使用最佳模型\n",
    "best_dt = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b623b649",
   "metadata": {},
   "source": [
    "##### 支持向量机分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad95fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC   \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('data/分类/sonar.all-data.csv', header=None)\n",
    "\n",
    "\n",
    "# 提取特征与标签\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# 标签转换为0/1\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"标签编码映射：\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# 绘制数据分布\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,0], X[:,1], c=y)\n",
    "\n",
    "# 划分训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def polySVC(degree, C=1.0):\n",
    "    return Pipeline(\n",
    "        [\n",
    "            ('std',StandardScaler()),\n",
    "            ('kernelSVC',SVC(kernel='poly',degree=degree,C=C))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# 网格搜索\n",
    "param_grid = {\n",
    "    'kernelSVC__degree': [2,3,4],\n",
    "    'kernelSVC__C': [0.1,1,10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=polySVC(degree=2), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 打印最佳参数\n",
    "print(\"最佳参数：\", grid_search.best_params_)\n",
    "\n",
    "# 预测与评估\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"准确率：\", accuracy_score(y_test, y_pred))\n",
    "print(\"分类报告：\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d1660",
   "metadata": {},
   "source": [
    "##### 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b215a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3797454494.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)import pandas as pd\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('data/分类/sonar.all-data.csv', header=None)\n",
    "\n",
    "# 提取特征与标签\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# 标签转换为0/1\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(\"标签编码映射：\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# 划分训练集与测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d69f3a",
   "metadata": {},
   "source": [
    "#### 回归-房价数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda3b08",
   "metadata": {},
   "source": [
    "##### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e25118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "df_train = pd.read_csv('data/回归类/train.csv')\n",
    "df_test = pd.read_csv('data/回归类/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394cfff",
   "metadata": {},
   "source": [
    "##### 数据查看和清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 读取数据\n",
    "df_train = pd.read_csv('data/回归类/train.csv')\n",
    "df_test = pd.read_csv('data/回归类/test.csv')\n",
    "\n",
    "# 1. 分离目标列\n",
    "y_train = df_train['SalePrice']\n",
    "df_train = df_train.drop('SalePrice', axis=1)\n",
    "\n",
    "# 2. 删除高缺失值列（>200个缺失值）\n",
    "train_null_counts = df_train.isnull().sum()\n",
    "test_null_counts = df_test.isnull().sum()\n",
    "\n",
    "train_cols_to_drop = train_null_counts[train_null_counts > 200].index\n",
    "test_cols_to_drop = test_null_counts[test_null_counts > 200].index\n",
    "cols_to_drop = set(train_cols_to_drop).union(set(test_cols_to_drop))\n",
    "\n",
    "df_train = df_train.drop(cols_to_drop, axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# 3. 填充缺失值\n",
    "def fill_missing_values(df):\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "df_train = fill_missing_values(df_train)\n",
    "df_test = fill_missing_values(df_test)\n",
    "\n",
    "# 4. 识别分类列\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns.tolist()\n",
    "non_cat_cols = [col for col in df_train.columns if col not in categorical_cols]\n",
    "\n",
    "# 5. One-Hot编码处理\n",
    "print(\"\\n使用One-Hot Encoding处理分类变量...\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 拟合和转换\n",
    "preprocessor.fit(df_train)\n",
    "train_encoded = preprocessor.transform(df_train)\n",
    "test_encoded = preprocessor.transform(df_test)\n",
    "\n",
    "# 获取特征名称\n",
    "ohe_feature_names = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "all_feature_names = np.concatenate([ohe_feature_names, non_cat_cols])\n",
    "\n",
    "# 重建DataFrame（确保形状匹配）\n",
    "X_train = pd.DataFrame(train_encoded, columns=all_feature_names)\n",
    "X_test = pd.DataFrame(test_encoded, columns=all_feature_names)\n",
    "\n",
    "# 6. 验证处理结果\n",
    "print('\\n处理后训练集特征形状:', X_train.shape)\n",
    "print('处理后测试集特征形状:', X_test.shape)\n",
    "print('训练集目标形状:', y_train.shape)\n",
    "\n",
    "# 7. 数据标准化（Lasso对特征的尺度敏感）\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 8. Lasso回归模型\n",
    "# 初始化Lasso模型，alpha是正则化强度\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000, random_state=42)\n",
    "\n",
    "# 9. 交叉验证\n",
    "# 使用负均方误差作为评分标准（scikit-learn默认使用高分好）\n",
    "neg_mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "cv_scores = cross_val_score(lasso, X_train_scaled, y_train, \n",
    "                          cv=5, scoring=neg_mse_scorer)\n",
    "\n",
    "# 将负MSE转换为正MSE并计算均方根误差(RMSE)\n",
    "rmse_scores = np.sqrt(-cv_scores)\n",
    "print(\"\\n交叉验证RMSE分数:\", rmse_scores)\n",
    "print(f\"最佳得分: {rmse_scores.min():.4f}\" )\n",
    "print(\"平均RMSE: {:.4f} (±{:.4f})\".format(rmse_scores.mean(), rmse_scores.std()))\n",
    "\n",
    "# 10. 训练最终模型\n",
    "lasso.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接取出数据集中没有空值的列作为新的训练集和测试集\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "df_train = pd.read_csv('data/回归类/train.csv')\n",
    "df_test = pd.read_csv('data/回归类/test.csv')\n",
    "\n",
    "# 找出训练集中没有空值的列\n",
    "train_non_null_columns = df_train.columns[df_train.isnull().sum() == 0]\n",
    "# 找出测试集中没有空值的列\n",
    "test_non_null_columns = df_test.columns[df_test.isnull().sum() == 0]\n",
    "\n",
    "# 找出两个数据集中都有的没有空值的列\n",
    "common_non_null_columns = list(set(train_non_null_columns).intersection(set(test_non_null_columns)))\n",
    "\n",
    "# 选取这些列作为新的训练集和测试集\n",
    "new_df_train = df_train[common_non_null_columns].copy()  # 使用.copy()确保是一个新的DataFrame而不是视图\n",
    "new_df_test = df_test[common_non_null_columns].copy()\n",
    "\n",
    "# 筛选出 object 类型（通常为分类变量）的列\n",
    "object_columns = new_df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 对每个 object 类型的列进行标签编码\n",
    "for col in object_columns:\n",
    "    le = LabelEncoder()\n",
    "    # 在训练集上拟合和转换，使用.loc明确索引\n",
    "    new_df_train.loc[:, col] = le.fit_transform(new_df_train[col])\n",
    "    # 在测试集上只进行转换，使用.loc明确索引\n",
    "    new_df_test.loc[:, col] = le.transform(new_df_test[col])\n",
    "\n",
    "X_train = new_df_train.values\n",
    "y_train = df_train['SalePrice'].values\n",
    "X_test = new_df_test.values\n",
    "\n",
    "# 开始训练模型 Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# 预测测试集\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a542a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 加载训练集和测试集\n",
    "df_train = pd.read_csv('data/回归类/train.csv')\n",
    "df_test = pd.read_csv('data/回归类/test.csv')\n",
    "\n",
    "# 处理训练集缺失值\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        df_train[col] = df_train[col].fillna(df_train[col].mode()[0])\n",
    "    else:\n",
    "        df_train[col] = df_train[col].fillna(df_train[col].mean())\n",
    "\n",
    "# 处理测试集缺失值\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'object':\n",
    "        df_test[col] = df_test[col].fillna(df_test[col].mode()[0])\n",
    "    else:\n",
    "        df_test[col] = df_test[col].fillna(df_test[col].mean())\n",
    "\n",
    "# 对训练集和测试集的非数值型列进行独热编码\n",
    "cat_cols_train = df_train.select_dtypes(include=['object']).columns\n",
    "cat_cols_test = df_test.select_dtypes(include=['object']).columns\n",
    "\n",
    "df_train_encoded = pd.get_dummies(df_train, columns=cat_cols_train)\n",
    "df_test_encoded = pd.get_dummies(df_test, columns=cat_cols_test)\n",
    "\n",
    "# 确保训练集和测试集编码后的列一致\n",
    "# 找出训练集有但测试集没有的列\n",
    "extra_cols_train = set(df_train_encoded.columns) - set(df_test_encoded.columns)\n",
    "for col in extra_cols_train:\n",
    "    df_test_encoded[col] = 0\n",
    "\n",
    "# 找出测试集有但训练集没有的列\n",
    "extra_cols_test = set(df_test_encoded.columns) - set(df_train_encoded.columns)\n",
    "df_test_encoded = df_test_encoded.drop(columns=extra_cols_test)\n",
    "\n",
    "# 按相同顺序排列列\n",
    "df_test_encoded = df_test_encoded[df_train_encoded.columns]\n",
    "\n",
    "# 准备训练数据和目标变量\n",
    "X_train = df_train_encoded.drop(columns=['Id', 'SalePrice'])\n",
    "y_train = df_train_encoded['SalePrice']\n",
    "\n",
    "# 确保 X_test 不包含 SalePrice 列\n",
    "X_test = df_test_encoded.drop(columns=['Id', 'SalePrice'], errors='ignore')\n",
    "\n",
    "# 初始化随机森林回归模型\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 将预测结果添加到测试集中\n",
    "df_test['Predicted_SalePrice'] = y_pred\n",
    "\n",
    "# 将结果保存为 CSV 文件\n",
    "df_test.to_csv('data/回归类/test_with_predictions.csv', index=False)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 从训练集划分出验证集\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化随机森林回归模型\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 在训练子集上训练模型\n",
    "rf.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_val_pred = rf.predict(X_val)\n",
    "\n",
    "# 计算均方误差\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "# 计算均方根误差\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# 计算 R² 分数\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"均方误差 (MSE): {mse}\")\n",
    "print(f\"均方根误差 (RMSE): {rmse}\")\n",
    "print(f\"R² 分数: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02548c36",
   "metadata": {},
   "source": [
    "#### 多模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e024f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 加载数据\n",
    "train_df = pd.read_csv('data/回归类/train.csv')\n",
    "test_df = pd.read_csv('data/回归类/test.csv')\n",
    "\n",
    "# 数据探索\n",
    "print(\"训练集基本信息:\")\n",
    "print(train_df.info())\n",
    "print(\"\\n训练集统计描述:\")\n",
    "print(train_df.describe())\n",
    "print(\"\\n训练集缺失值统计:\")\n",
    "missing_values = train_df.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# 目标变量分析\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_df['SalePrice'], kde=True)\n",
    "plt.title('房价分布')\n",
    "plt.savefig('price_distribution.png')\n",
    "\n",
    "# 特征相关性分析\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = train_df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=False)\n",
    "plt.title('特征相关性热力图')\n",
    "plt.savefig('correlation_heatmap.png')\n",
    "\n",
    "# 数据预处理\n",
    "X = train_df.drop(['Id', 'SalePrice'], axis=1)\n",
    "y = train_df['SalePrice']\n",
    "X_test = test_df.drop('Id', axis=1)\n",
    "\n",
    "# 分离数值型和分类型特征\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 创建预处理管道\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# 模型训练与评估\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # 交叉验证\n",
    "    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    results[name] = cv_rmse\n",
    "    print(f\"{name} CV RMSE: {cv_rmse:.4f}\")\n",
    "\n",
    "# 选择最佳模型进行调参\n",
    "best_model_name = min(results, key=results.get)\n",
    "print(f\"\\n最佳模型: {best_model_name}\")\n",
    "\n",
    "# 对最佳模型进行参数调优\n",
    "if best_model_name == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 4, 5]\n",
    "    }\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingRegressor(random_state=42))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"最佳参数: {grid_search.best_params_}\")\n",
    "    print(f\"调优后CV RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")\n",
    "else:\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', models[best_model_name])\n",
    "    ])\n",
    "    pipeline.fit(X, y)\n",
    "    best_model = pipeline\n",
    "\n",
    "# 特征重要性分析（仅适用于树模型）\n",
    "if hasattr(best_model['model'], 'feature_importances_'):\n",
    "    # 获取特征名称\n",
    "    ohe = best_model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_features = ohe.get_feature_names_out(categorical_features)\n",
    "    all_features = np.concatenate([numeric_features, cat_features])\n",
    "    \n",
    "    # 获取特征重要性\n",
    "    importances = best_model['model'].feature_importances_\n",
    "    indices = np.argsort(importances)[-10:]  # 取前10个重要特征\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(indices)), importances[indices])\n",
    "    plt.yticks(range(len(indices)), [all_features[i] for i in indices])\n",
    "    plt.xlabel('特征重要性')\n",
    "    plt.title('Top 10 特征重要性')\n",
    "    plt.savefig('feature_importance.png')\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# 生成提交文件\n",
    "submission = pd.DataFrame({\n",
    "    'Id': test_df['Id'],\n",
    "    'SalePrice': y_pred\n",
    "})\n",
    "submission.to_csv('house_price_predictions.csv', index=False)\n",
    "print(\"预测结果已保存到 house_price_predictions.csv\")\n",
    "\n",
    "# 模型评估报告\n",
    "print(\"\\n=== 模型评估报告 ===\")\n",
    "for name, rmse in results.items():\n",
    "    print(f\"{name}: RMSE = {rmse:.4f}\")\n",
    "\n",
    "# 可视化数据准备\n",
    "sample_data = train_df.sample(n=10, random_state=42)[['Id', 'OverallQual', 'GrLivArea', 'GarageCars', 'YearBuilt', 'SalePrice']]\n",
    "model_performance = pd.DataFrame(list(results.items()), columns=['Model', 'RMSE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
